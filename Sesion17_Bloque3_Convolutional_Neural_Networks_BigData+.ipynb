{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496631ea",
   "metadata": {
    "id": "496631ea"
   },
   "source": [
    "# Módulo 1: Análisis de datos en el ecosistema Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14cd3f",
   "metadata": {
    "id": "3a14cd3f"
   },
   "source": [
    "### Sesión (17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd93e7",
   "metadata": {
    "id": "6acd93e7"
   },
   "source": [
    "**23/01/2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaae337",
   "metadata": {
    "id": "fbaae337"
   },
   "source": [
    "## Clasificación de imágenes con redes neuronales convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d25f9",
   "metadata": {
    "id": "184d25f9"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4ad81",
   "metadata": {
    "id": "63c4ad81"
   },
   "source": [
    "Las **[redes neuronales convolucionales (CNN) o _ConvNet_](https://es.wikipedia.org/wiki/Red_neuronal_convolucional)** son una variación de redes neuronales profundas (DNN) o perceptrón multicapa (MLP) que **se aplican sobre las matrices bidimensionales como imágenes**. Estas redes consisten en **múltiples capas de filtros convolucionales que procesan la información en una manera muy parecida al cortex visual del ojo humano**, por lo tanto son muy efectivas para tareas de **visión artificial**, clasificación y segmentación de imágenes, entre otras aplicaciones.\n",
    "\n",
    "En otro tipo de problemas de clasificación, **siempre se procesan los datos para llegar a determinar las variables o los _features_** que caracterizan a una observación. En caso de _visión artificial_, donde cada observación es una imágen, también debemos llegar a **definir un conjunto preferiblemente reducido de características** para después desarrollar un clasificador basado en esos aspectos. \n",
    "\n",
    "Por este motivo, al **principio** de una red neuronal convolucional se encuentra **la fase de extracción de _features_** o características, donde **al igual que el proceso estimulante en las células del cortex visual**, se forman los atributos más importantes y **se disminuye la dimensionalidad** mediante la aplicación de **varias capas convolucionales y de reducción de muestreo**.\n",
    "\n",
    "Después, se encuentran neuronas de perceptrón sencillas en una **estructura densa (_fully-connected_)** que realizan la **clasificación final** sobre las características extraídas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62b949",
   "metadata": {
    "id": "1d62b949"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3a800",
   "metadata": {
    "id": "29e3a800"
   },
   "source": [
    "### Procesado convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382b480",
   "metadata": {
    "id": "c382b480"
   },
   "source": [
    "Sabemos que los imágenes no son más que grupos de píxeles juntos. Una **imagen RGB** no es más que una **matriz de valores de píxeles** que tiene **tres nivels de información**, mientras que una imagen en **escala de grises** se representa con una matriz en **un plano**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a675d0d",
   "metadata": {
    "id": "8a675d0d"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f367614",
   "metadata": {
    "id": "6f367614"
   },
   "source": [
    "Una técnica común consiste en **normalizar estos valores** antes de proceder a entrenar el modelo de la red neuronal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525bf76a",
   "metadata": {
    "id": "525bf76a"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9614d27",
   "metadata": {
    "id": "d9614d27"
   },
   "source": [
    "La **convolución** consiste en **extraer localmente las características** y los patrones específicos de los objetos presentes en una imagen. Para ello se consideran **grupos de pixeles adyacentes** de la imagen para sacar el producto escalar (convolución) contra un pequeño filtro o mejor dicho una matriz llamada **`kernel`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a2b9c",
   "metadata": {
    "id": "d70a2b9c"
   },
   "source": [
    "![Conv_no_padding_strides.gif](attachment:Conv_no_padding_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e182585",
   "metadata": {
    "id": "6e182585"
   },
   "source": [
    "Ese **filtro** o kernel (por ejemplo de tamaño 3×3 pixels) **recorre toda la imagen** generalmente de izquierda a derecha y de arriba hasta abajo, para obtener la función convolucionada. La matriz resultante se pasa a la siguiente capa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c76af",
   "metadata": {
    "id": "f41c76af"
   },
   "source": [
    "![11178fil.gif](attachment:11178fil.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d0ede",
   "metadata": {
    "id": "3e3d0ede"
   },
   "source": [
    "Paras las imágenes en **color (RGB)** sea aplicarán en realidad **3 kernels diferentes** (por ejemplo de 3×3) a cada canal. Después, se **suman los resultados** también con un valor de **sesgo (_bias_)** para obtener una única salida al igual que el caso de un solo canal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b85eb",
   "metadata": {
    "id": "442b85eb"
   },
   "source": [
    "![1_ciDgQEjViWLnCbmX-EeSrA.gif](attachment:1_ciDgQEjViWLnCbmX-EeSrA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8f127",
   "metadata": {
    "id": "fbc8f127"
   },
   "source": [
    "A la matriz convolucionada se le aplica una **función de activación** para añadir la **no-linealidad** al igaul que en otros tipos de redes neuronales. La función más utilizada es ___Relu___, donde se filtran todos los píxeles con valores negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bbeaf",
   "metadata": {
    "id": "330bbeaf"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16435041",
   "metadata": {
    "id": "16435041"
   },
   "source": [
    "En realidad, **no sólo se utiliza un _kernel_**, si no que se aplican varios kernels como un conjunto de **filtros**. Por lo tanto tendremos **varias matrices de salida** que en su conjunto se conocen como **`feature mapping`**. \n",
    "\n",
    "La **primera convolución** permite a la red que detecte **características básicas**, generalmente como lineas o curvas. Conforme se aumenta el número de capas ocultas convolucionales, los mapas de características reconocen aspectos y patrones más complejos.\n",
    "\n",
    "Al terminar la fase convolucional, cuando se dispone de un conjunto de características o un _fearture mapping_ que representa los rasgos y los atributos más identificativos de los objetos que se deben reconocer, pasamos a **la fase de clasificación** como otros tipos de rdes neuronales, **aplanando el conjunto final de los _features_** mediante una capa llamada **`flatten layer`** que nos permite desarrollar una **red neuronal con capas densas (_fully-connected_)** apartir de ese conjunto de características extraídas.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37326946",
   "metadata": {
    "id": "37326946"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efeb03",
   "metadata": {
    "id": "13efeb03"
   },
   "source": [
    "Al final de la estructura definida y montada de la red neuronal convolucional, necesitamos que **la capa final tenga los nodos suficientes** para que el modelo acabe clasificando los objetos reconocidos según el número de categorías o clases existentes en el dataset. Este paso se suele aplicar mediante la función **`softmax`** que es equivalente a **`sigmoid`** pero asigna probabilidades (valores entre 0 y 1) a cada clase para un problema de **clasificación multi-clase**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec4542",
   "metadata": {
    "id": "0fec4542"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c7407",
   "metadata": {
    "id": "5c8c7407"
   },
   "source": [
    "### Ejemplo de reconocimiento de numeros manuscritos (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346210a",
   "metadata": {
    "id": "8346210a"
   },
   "source": [
    "Vamos a realizar un ejercicio para desarrollar un clasificador que **sea capaz de recibir una imágen de un número escrito a mano y decidir a qué dígito corresponde**. El dataset **[MNIST](http://yann.lecun.com/exdb/mnist/)** contiene una serie de imágenes de números manuscritos. Por defecto al cargarse mediante librería _keras_, se dispone de un conjunto de datos de **60.000 imágenes** en **escala de grises** como conjunto de **entrenamiento** de tamaño **28x28** píxeles para los **10 dígitos**, además de un conjunto de **prueba** de **10.000 imágenes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a1419",
   "metadata": {
    "id": "1d4a1419"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.11.0 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# importamos las librerías necesarias \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d67e37",
   "metadata": {
    "id": "14d67e37"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.11.0 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Modificamos los parámetros de los gráficos en matplotlib\n",
    "from matplotlib.pyplot import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 6 # el primer dígito es el ancho y el segundo el alto\n",
    "rcParams[\"font.weight\"] = \"bold\"\n",
    "rcParams[\"font.size\"] = 10\n",
    "rcParams[\"axes.labelweight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94808235",
   "metadata": {
    "id": "94808235"
   },
   "source": [
    "### Cargar los datos (imágenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8161e",
   "metadata": {
    "id": "c2d8161e",
    "outputId": "1b06fe51-7a6e-4214-a492-07dbdec0041e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.11.0 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cargar el dataset desde la librería keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f8cf7",
   "metadata": {
    "id": "437f8cf7",
    "outputId": "8e6dc122-7478-4f73-b2d3-e5e05945abb2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Consultar los registros del DataFrame\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0f119",
   "metadata": {
    "id": "a7f0f119",
    "outputId": "fcbdede2-5bc0-4505-e631-59f396788902",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"El tipo de datos de entrada (training): \", type(X_train))\n",
    "print(\"La dimensión de datos de entrada (training):\", X_train.ndim)\n",
    "print(\"El tamaño de datos de entrada (training):\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570563b",
   "metadata": {
    "id": "b570563b",
    "outputId": "1bdc390c-dac5-4321-c48d-8f7ec780229c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"El tipo de datos de entrada (test): \", type(X_test))\n",
    "print(\"La dimensión de datos de entrada (test):\", X_test.ndim)\n",
    "print(\"El tamaño de datos de entrada (test):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc8759",
   "metadata": {
    "id": "fcbc8759"
   },
   "source": [
    "Las imágenes son 28x28 = 784 píxeles en escala de grises (negro y blanco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c67831",
   "metadata": {
    "id": "a7c67831",
    "outputId": "ca733385-6bb4-4ea9-d83d-6baffecebe83",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# La segunda imágen del conjunto de entrenamiento\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443efc00",
   "metadata": {
    "id": "443efc00"
   },
   "source": [
    "Podemos utilizar el método `imshow` de _matplotly_ para hacer una visualización rápida y comparar la imágen con su valor asociado en las etiquetas de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f05027",
   "metadata": {
    "id": "57f05027",
    "outputId": "fdeade13-b94c-4ad5-a12a-106647e8477b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[100], cmap='gray')\n",
    "print(\"La etiqueta asociada a este dígito es: \", y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be00ca",
   "metadata": {
    "id": "f2be00ca"
   },
   "source": [
    "Cada carácter ocupa un \"_byte_\" que se forma por ocho \"_bits_\": **$2^8=256$** El valor de cada píxel varía de _0_ a _255_.  \n",
    "El tipo __uint8__ en _numpy_ significa: `Unsigned integer (0 to 255)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988a05c",
   "metadata": {
    "id": "0988a05c",
    "outputId": "6cb04c53-6a42-4829-dfe6-ea9356fe2320",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.dtype)\n",
    "print(X_train.min())\n",
    "print(X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b651fed",
   "metadata": {
    "id": "4b651fed"
   },
   "source": [
    "Las salidas del modelo serían los dígitos asociados a cada imágen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ac57d",
   "metadata": {
    "id": "9e5ac57d",
    "outputId": "a51fea2e-b7f1-4e2a-fed1-2633adbe931f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243b90b",
   "metadata": {
    "id": "7243b90b",
    "outputId": "e4dba06a-3e91-4085-caab-35f3124a49a8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"El tipo de datos de salida (training): \", type(y_train))\n",
    "print(\"La dimensión de datos de salida (training):\", y_train.ndim)\n",
    "print(\"El tamaño de datos de salida (training):\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31255af",
   "metadata": {
    "id": "f31255af"
   },
   "source": [
    "Consultamos las **frecuencias de los dígitos**. Es muy importante que el modelo se entrene con un **conjunto equilibrado** de datos que idealmente tenga una **representación igual** para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96900243",
   "metadata": {
    "id": "96900243",
    "outputId": "6e852a65-f7a6-4e9c-d120-f3547bafa177",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# El histograma de los dígitos presentes en el dataset\n",
    "pd.Series(y_train).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf0153",
   "metadata": {
    "id": "bfcf0153"
   },
   "source": [
    "Para que los datos utilizados en la creación del modelo tengan **una escala estándar**, procedemos primero a **normalizar los datos de entrada** de esta manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617cf90",
   "metadata": {
    "id": "3617cf90",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Vamos a escalar los valores de nuestras arrays para que se convierten en valores entre 0 y 1\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f50f27",
   "metadata": {
    "id": "83f50f27",
    "outputId": "edeab387-4078-4e0b-b2f9-f7b60317e44f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Valores normalizados\n",
    "pd.Series(X_train_norm.flatten()).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0decb",
   "metadata": {
    "id": "d6c0decb"
   },
   "source": [
    "Ahora tenemos que tratar la salida que son dígitos de 0 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff89d1b",
   "metadata": {
    "id": "4ff89d1b",
    "outputId": "aba9e32d-8d52-436a-c0db-e7cd089b85bf",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa33dea",
   "metadata": {
    "id": "2aa33dea"
   },
   "source": [
    "Debemos **estandarizar** también estos valores para la **variable objetivo**. Sin embargo, no queremos que tomen valores tipo `float` con decimales, porque **la salida de nuestra red sería una probabilidad para cada dígito o cada clase**. tenemos que construir nuestra red neuronal con **10 neuronas en la capa de salida**.  \n",
    "\n",
    "El algoritmo no puede comparar un vector de 10 valores con un solo valor objetivo. Para ello, **convertimos cada valor objetivo en un vector de longitud 10**, usando la técnica de `One-hot encoding`:\n",
    "\n",
    "- El valor `0` de la variable objetivo se convierte en `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]`  \n",
    "- El valor `1` de la variable objetivo se convierte en `[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`  \n",
    "- El valor `2` de la variable objetivo se convierte en `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]`  \n",
    "- ...\n",
    "- El valor `9` de la variable objetivo se convierte en `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ddf917",
   "metadata": {
    "id": "30ddf917",
    "outputId": "4bc68930-0e84-449f-d8bc-278a50d1e5ae",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# La codificación one-hot se puede realizar fácilmente con las utilidades proporcionadas por Keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "to_categorical(y_train, dtype='uint8')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b80d11",
   "metadata": {
    "id": "d2b80d11",
    "outputId": "97853fd6-d3c9-4776-9797-dd80ffaf577d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# La codificación one-hot se puede realizar fácilmente con las utilidades proporcionadas por Keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_norm = to_categorical(y_train, dtype='uint8')\n",
    "y_test_norm = to_categorical(y_test, dtype='uint8')\n",
    "\n",
    "print(\"Etiqueta de la segunda imágen: \", y_train[1])\n",
    "print(\"Etiqueta normalizada de la segunda imágen: \", y_train_norm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202ebc9",
   "metadata": {
    "id": "8202ebc9"
   },
   "source": [
    "Ahora necesitamos **redimensionar los conjuntos de datos de entrada (X_train y X_test)** a la forma que espera nuestra red de las imágenes.\n",
    "- El **primer** número es el **número de imágenes** (60.000 para X_train y 10.000 para X_test).  \n",
    "- Después viene la forma de **cada imagen (28x28)**.  \n",
    "- El último número habla de **la escala de los valores de cada píxel**. En este caso sería 1, lo que significa que las imágenes están en **escala gris** (negro y blanco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345ea61",
   "metadata": {
    "id": "7345ea61",
    "outputId": "f6ffa7ad-fa38-4ef4-fd0b-ca66656753dc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Vamos a redimensionar los datos normalizados de entrada\n",
    "x_train = X_train_norm.reshape(len(X_train_norm),28,28,1)\n",
    "x_test = X_test_norm.reshape(len(X_test_norm),28,28,1)\n",
    "\n",
    "print(\"El tamaño de datos de entrada (training):\", x_train.shape)\n",
    "print(\"El tamaño de datos de entrada (test):\", x_test.shape)\n",
    "\n",
    "print(\"El tamaño de entrada a la red:\", x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105421ab",
   "metadata": {
    "id": "105421ab"
   },
   "source": [
    "Antes de desarrollar una **red neuronal convolucional (CNN)**, intentamos crear una **red neuronal profunda (DNN)** sin la fase de convolución y con las capas densas utilizadas en otros problemas distintos que reconocimiento de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e6153",
   "metadata": {
    "id": "458e6153",
    "outputId": "0ce7edac-dc7b-4fff-d18d-f4c000a614a4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# importar los módulos, las clases y las funciones a utilizar\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from keras.backend import clear_session\n",
    "\n",
    "# Resetear el estado global de keras\n",
    "clear_session()\n",
    "\n",
    "# Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "semilla = 333\n",
    "random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "\n",
    "\n",
    "# Declarar el modelo que se va a crear\n",
    "modelo_dnn = Sequential()\n",
    "\n",
    "# Definir la entrada a la red que son imágenes (28,28,1)\n",
    "modelo_dnn.add(Input(shape=x_train[0].shape))\n",
    "\n",
    "# Debemos aplanar la matriz de cada imágen para pasarlos a las capas densas (fully-connected) \n",
    "modelo_dnn.add(Flatten())\n",
    "\n",
    "# Definir las capas ocultas\n",
    "modelo_dnn.add(Dense(100, activation='relu'))\n",
    "modelo_dnn.add(Dense(200, activation='relu'))\n",
    "modelo_dnn.add(Dense(100, activation='relu'))\n",
    "\n",
    "# La capa de salida con el tamaño de la respuesta\n",
    "modelo_dnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar e indicar los ajustes del modelo\n",
    "modelo_dnn.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Consultar el resumen del modelo definido\n",
    "modelo_dnn.summary()\n",
    "\n",
    "# Ajustar el modelo a los datos del entrenamiento.\n",
    "registros = modelo_dnn.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=3, batch_size=1000)\n",
    "\n",
    "# Calcular las predicciones para el conjunto de test \n",
    "y_pred_dnn = modelo_dnn.predict(x_test)\n",
    "\n",
    "\n",
    "# Filtrar las predicciones y evaluar el modelo\n",
    "y_pred_dnn_filt = np.where(y_pred_dnn < 0.5, 0, 1)\n",
    "print('Acuuracy:', accuracy_score(y_test_norm, y_pred_dnn_filt))\n",
    "print('AUC:', roc_auc_score(y_test_norm, y_pred_dnn_filt))\n",
    "\n",
    "# Graficamos la evolución de error (Logic Loss)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros.epoch, registros.history['loss'], linewidth=3, label='training Log-Loss')\n",
    "plt.plot(registros.epoch, registros.history['val_loss'], linewidth=3, label='test Log-Loss')\n",
    "plt.xticks(registros.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('La evolución de error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos la evolución del porcentaje de acierto (Accuracy)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros.epoch, registros.history['accuracy'], linewidth=3, label='training Accuracy')\n",
    "plt.plot(registros.epoch, registros.history['val_accuracy'], linewidth=3, label='test Accuracy')\n",
    "plt.xticks(registros.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('La evolución del porcentaje de acierto')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9f4a4",
   "metadata": {
    "id": "47c9f4a4"
   },
   "source": [
    "Como se puede ver los resultados son bastante aceptables, como se puede ver el rendimiento para diferentes clases detectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89371f35",
   "metadata": {
    "id": "89371f35",
    "outputId": "1d7466f6-3dba-4dcf-ad4d-22cb21ee1e54",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_norm, y_pred_dnn_filt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac27ef4",
   "metadata": {
    "id": "4ac27ef4"
   },
   "source": [
    "Ahora creamos una red neuronal con **capas convolucionales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f6f83",
   "metadata": {
    "id": "595f6f83",
    "outputId": "d88b2d6a-827d-4aa6-f773-846f1bfd92d8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# importar los módulos, las clases y las funciones a utilizar\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from keras.backend import clear_session\n",
    "\n",
    "# Resetear el estado global de keras\n",
    "clear_session()\n",
    "\n",
    "# Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "semilla = 333\n",
    "random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "\n",
    "\n",
    "# Declarar el modelo que se va a crear\n",
    "modelo_cnn = Sequential()\n",
    "modelo_cnn.add(Input(shape=x_train[0].shape))\n",
    "modelo_cnn.add(Conv2D(filters=10, kernel_size=(4,4), activation='relu'))\n",
    "modelo_cnn.add(Flatten())\n",
    "modelo_cnn.add(Dense(50, activation='relu'))\n",
    "modelo_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar e indicar los ajustes del modelo\n",
    "modelo_cnn.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Consultar el resumen del modelo definido\n",
    "modelo_cnn.summary()\n",
    "\n",
    "# Ajustar el modelo a los datos del entrenamiento.\n",
    "registros = modelo_cnn.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=3, batch_size=1000)\n",
    "\n",
    "# Calcular las predicciones para el conjunto de test \n",
    "y_pred_cnn = modelo_cnn.predict(x_test)\n",
    "\n",
    "\n",
    "# Filtrar las predicciones y evaluar el modelo\n",
    "y_pred_cnn_filt = np.where(y_pred_cnn < 0.5, 0, 1)\n",
    "print('Acuuracy:', accuracy_score(y_test_norm, y_pred_cnn_filt))\n",
    "print('AUC:', roc_auc_score(y_test_norm, y_pred_cnn_filt))\n",
    "\n",
    "# Graficamos la evolución de error (Logic Loss)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros.epoch, registros.history['loss'], linewidth=3, label='training Log-Loss')\n",
    "plt.plot(registros.epoch, registros.history['val_loss'], linewidth=3, label='test Log-Loss')\n",
    "plt.xticks(registros.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('La evolución de error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos la evolución del porcentaje de acierto (Accuracy)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros.epoch, registros.history['accuracy'], linewidth=3, label='training Accuracy')\n",
    "plt.plot(registros.epoch, registros.history['val_accuracy'], linewidth=3, label='test Accuracy')\n",
    "plt.xticks(registros.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('La evolución del porcentaje de acierto')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30de97e",
   "metadata": {
    "id": "f30de97e"
   },
   "source": [
    "Primero echamos un vistazo a los parámetros o mejor dicho **los pesos de la red** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bdf5d",
   "metadata": {
    "id": "667bdf5d",
    "outputId": "4fa76473-2870-432e-e538-53c4baa277ec",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "modelo_cnn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5fe53",
   "metadata": {
    "id": "64a5fe53",
    "outputId": "671a719e-ef3e-4b9f-9cdc-b36df6f8a2fd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Consultamos las etiquetas normalizadas del conjunto de test\n",
    "y_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c7a9e",
   "metadata": {
    "id": "f46c7a9e",
    "outputId": "017ae67c-6ab9-455e-dda7-08fc99ab37a4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Consultamos las predicciones filtradas del modelo para el conjunto de test\n",
    "y_pred_cnn_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67861093",
   "metadata": {
    "id": "67861093",
    "outputId": "94100d01-17ad-4ba1-e9f5-fa68d65cfe67",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Consultamos la salida cruda del modelo para el conjunto de test\n",
    "y_pred_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3b413",
   "metadata": {
    "id": "75a3b413"
   },
   "source": [
    "Vamos a investigar la distribución y el rango de **la salida directa de la red** que serían las **probabilidades** de que si pertenece una imágen a una clase o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8597cc",
   "metadata": {
    "id": "6a8597cc",
    "outputId": "367a2b55-1c73-4093-c298-493413c3f56a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Las características estadística de las predicciones sin filtrar\n",
    "pd.Series(y_pred_cnn.flatten()).describe().round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a71ae",
   "metadata": {
    "id": "d86a71ae"
   },
   "source": [
    "Por ser valores **muy concentrados cerca de 0 y de 1**, no hay ninguna preocupación a la hora de determinar el **umbral** final para el filtro de las predicciones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53640cd1",
   "metadata": {
    "id": "53640cd1",
    "outputId": "cd868724-c179-4a4a-bf86-95a982634d76",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# El histograma de las probabilidades resultantes del modelo \n",
    "pd.Series(y_pred_cnn.flatten()).hist(bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986889e9",
   "metadata": {
    "id": "986889e9"
   },
   "source": [
    "Ahora vamos a crear una nueva red con más capas convolucionales. Intentamos desarrollar un modelo concorde a la estructura representada en este ejemplo: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a4d5e",
   "metadata": {
    "id": "429a4d5e"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af17a0",
   "metadata": {
    "id": "c9af17a0",
    "outputId": "da37d218-5525-4f0f-e861-589d81bd5913",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# importar los módulos, las clases y las funciones a utilizar\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from keras.backend import clear_session\n",
    "\n",
    "# Resetear el estado global de keras\n",
    "clear_session()\n",
    "\n",
    "# Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "semilla = 333\n",
    "random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "\n",
    "\n",
    "# Declarar el modelo que se va a crear\n",
    "modelo_cnn2 = Sequential()\n",
    "modelo_cnn2.add(Input(shape=x_train[0].shape))\n",
    "modelo_cnn2.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "modelo_cnn2.add(Conv2D(filters=36, kernel_size=(5,5), activation='relu'))\n",
    "modelo_cnn2.add(Flatten())\n",
    "modelo_cnn2.add(Dense(128, activation='relu'))\n",
    "modelo_cnn2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar e indicar los ajustes del modelo\n",
    "modelo_cnn2.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Consultar el resumen del modelo definido\n",
    "modelo_cnn2.summary()\n",
    "\n",
    "# Ajustar el modelo a los datos del entrenamiento.\n",
    "registros2 = modelo_cnn2.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=3, batch_size=1000)\n",
    "\n",
    "# Calcular las predicciones para el conjunto de test \n",
    "y_pred_cnn2 = modelo_cnn2.predict(x_test)\n",
    "\n",
    "\n",
    "# Filtrar las predicciones y evaluar el modelo\n",
    "y_pred_cnn_filt2 = np.where(y_pred_cnn2 < 0.5, 0, 1)\n",
    "print('Acuuracy:', accuracy_score(y_test_norm, y_pred_cnn_filt2))\n",
    "print('AUC:', roc_auc_score(y_test_norm, y_pred_cnn_filt2))\n",
    "\n",
    "# Graficamos la evolución de error (Logic Loss)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros2.epoch, registros2.history['loss'], linewidth=3, label='training Log-Loss')\n",
    "plt.plot(registros2.epoch, registros2.history['val_loss'], linewidth=3, label='test Log-Loss')\n",
    "plt.xticks(registros2.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('La evolución de error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos la evolución del porcentaje de acierto (Accuracy)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros2.epoch, registros2.history['accuracy'], linewidth=3, label='training Accuracy')\n",
    "plt.plot(registros2.epoch, registros2.history['val_accuracy'], linewidth=3, label='test Accuracy')\n",
    "plt.xticks(registros2.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('La evolución del porcentaje de acierto')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238e10e",
   "metadata": {
    "id": "3238e10e"
   },
   "source": [
    "Como se puede apreciar, los resultados del modelo, tanto en términos de **precisión** como de **evolución de la métrica de error (_Loss_)** en los dos conjuntos de entrenamiento y de prueba, sin duda son **muy acertados**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad505c13",
   "metadata": {
    "id": "ad505c13"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c360f33",
   "metadata": {
    "id": "7c360f33"
   },
   "source": [
    "### **`Ejercicio 17.1`**\n",
    "\n",
    "Crea una ___ConvNet___ basada en la estructura recomendada en el siguiente diagrama, considerando los siguientes puntos. Explica si este último modelo tiene un buen rendimiento comparando con modelos anteriores:\n",
    "- El tamaño de los _kernels_ aplicada en la capa convolucional es de (`3x3`).\n",
    "- `semilla=333`,\n",
    "- `epochs=3`,\n",
    "- `batch_size=1000`,\n",
    "- `umbral=0.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e04ec",
   "metadata": {
    "id": "1b5e04ec"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ea047",
   "metadata": {
    "id": "5a9ea047",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Solución\n",
    "# Ejercicio 17.1\n",
    "# importar los módulos, las clases y las funciones a utilizar\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from keras.backend import clear_session\n",
    "\n",
    "def ConvNet():\n",
    "    # Resetear el estado global de keras\n",
    "    clear_session()\n",
    "\n",
    "    # Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "    semilla = 333\n",
    "    random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "    np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "    tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "\n",
    "\n",
    "    # Declarar el modelo que se va a crear\n",
    "    modelo_cnn = Sequential()\n",
    "    modelo_cnn.add(Input(shape=x_train[0].shape))\n",
    "    modelo_cnn.add(Conv2D(filters=10, kernel_size=(3,3), activation='relu'))\n",
    "    modelo_cnn.add(Flatten())\n",
    "    modelo_cnn.add(Dense(50, activation='relu'))\n",
    "    modelo_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compilar e indicar los ajustes del modelo\n",
    "    modelo_cnn.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "    # Consultar el resumen del modelo definido\n",
    "    modelo_cnn.summary()\n",
    "\n",
    "    # Ajustar el modelo a los datos del entrenamiento.\n",
    "    registros = modelo_cnn.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=3, batch_size=1000)\n",
    "\n",
    "    # Calcular las predicciones para el conjunto de test \n",
    "    y_pred_cnn = modelo_cnn.predict(x_test)\n",
    "\n",
    "\n",
    "    # Filtrar las predicciones y evaluar el modelo\n",
    "    y_pred_cnn_filt = np.where(y_pred_cnn < 0.5, 0, 1)\n",
    "    print('Acuuracy:', accuracy_score(y_test_norm, y_pred_cnn_filt))\n",
    "    print('AUC:', roc_auc_score(y_test_norm, y_pred_cnn_filt))\n",
    "\n",
    "    # Graficamos la evolución de error (Logic Loss)\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(registros.epoch, registros.history['loss'], linewidth=3, label='training Log-Loss')\n",
    "    plt.plot(registros.epoch, registros.history['val_loss'], linewidth=3, label='test Log-Loss')\n",
    "    plt.xticks(registros.epoch)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('La evolución de error')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # Graficamos la evolución del porcentaje de acierto (Accuracy)\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(registros.epoch, registros.history['accuracy'], linewidth=3, label='training Accuracy')\n",
    "    plt.plot(registros.epoch, registros.history['val_accuracy'], linewidth=3, label='test Accuracy')\n",
    "    plt.xticks(registros.epoch)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('La evolución del porcentaje de acierto')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3bc3e",
   "metadata": {
    "id": "20e3bc3e"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3194b",
   "metadata": {
    "id": "35b3194b"
   },
   "source": [
    "### Reducción de dimensionalidad (___Sub-sampling___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02a5e0",
   "metadata": {
    "id": "fb02a5e0",
    "tags": []
   },
   "source": [
    "El último modelo entrenado (`modelo_cnn2`) con dos capas convolucionales y una capa oculta tipo _fully-connected_ ha llegado a tener unos **resultados perfectos**. Sin embargo, el **número de los parámetros** de esta red se podría considerar algo **elevado** (cerca de 2 millones) considerando que todavía no estamos ante una problematica muy complicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f08c10",
   "metadata": {
    "id": "51f08c10",
    "outputId": "8852d30c-65be-452d-fab8-0cad6bc5a54b",
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"El número total de los parámetros de la red (modelo_cnn): \", modelo_cnn2.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04fd30",
   "metadata": {
    "id": "6a04fd30"
   },
   "source": [
    "En las capas convolucionales, al mismo tiempo que **se aplican diferentes _kernels_** para sacar varias características representativas y **detectar diferentes patrones** presentes en las imágenes, se suelen aplicar también **una serie de técnicas de reducción de muestreo** tipo ___dawn-sampling___ o ___sub-sampling___ que intentan disminuir el tamaño de las características extraídas.  \n",
    "\n",
    "Mantener el tamaño de la imagen al pasar por los filtros de convolución hace que el **proceso de aprendizaje sea muy costoso por el número de neuronas y los pesos** asociados a los parémetros de la red neuronal. Para ello existen unas **capas llamadas ___Pooling___** que permiten reducir esos pesos del modelo y así agilizar el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b1f74",
   "metadata": {
    "id": "685b1f74"
   },
   "source": [
    "![max-pp2.gif](attachment:max-pp2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bebdbb",
   "metadata": {
    "id": "a8bebdbb"
   },
   "source": [
    "\n",
    "\n",
    "El método más usado en las capas de _Pooling_ se llama ___Max-Pooling___ que procura **mantener las características más importantes** que detecta cada filtro, **preservando el valor más alto** en una ventana (de 2x2 por ejemplo) y reduciendo a su vez el tamaño de las matrices de _feature mapping_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76171946",
   "metadata": {
    "id": "76171946"
   },
   "source": [
    "![max-p.gif](attachment:max-p.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7307b62",
   "metadata": {
    "id": "d7307b62"
   },
   "source": [
    "Ahora vamos a **incluir unas capas de tipo _Max-Pooling_** en nuestra red neuronal convolucional según la estructura representada en la siguiente gráfica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6b74",
   "metadata": {
    "id": "c2ab6b74"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d516595",
   "metadata": {
    "id": "1d516595",
    "outputId": "ad86eb8f-5908-439a-b6c8-72f5e6989cce",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# importar los módulos, las clases y las funciones a utilizar\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from keras.backend import clear_session\n",
    "\n",
    "# Resetear el estado global de keras\n",
    "clear_session()\n",
    "\n",
    "# Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "semilla = 333\n",
    "random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "\n",
    "\n",
    "# Declarar el modelo que se va a crear\n",
    "modelo_cnn_pool = Sequential()\n",
    "modelo_cnn_pool.add(Input(shape=x_train[0].shape))\n",
    "modelo_cnn_pool.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "modelo_cnn_pool.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo_cnn_pool.add(Conv2D(filters=36, kernel_size=(5,5), activation='relu'))\n",
    "modelo_cnn_pool.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelo_cnn_pool.add(Flatten())\n",
    "modelo_cnn_pool.add(Dense(128, activation='relu'))\n",
    "modelo_cnn_pool.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar e indicar los ajustes del modelo\n",
    "modelo_cnn_pool.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Consultar el resumen del modelo definido\n",
    "modelo_cnn_pool.summary()\n",
    "\n",
    "# Ajustar el modelo a los datos del entrenamiento.\n",
    "registros_pool = modelo_cnn_pool.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=3, batch_size=1000)\n",
    "\n",
    "# Calcular las predicciones para el conjunto de test \n",
    "y_pred_cnn_pool = modelo_cnn_pool.predict(x_test)\n",
    "\n",
    "\n",
    "# Filtrar las predicciones y evaluar el modelo\n",
    "y_pred_cnn_filt_pool = np.where(y_pred_cnn_pool < 0.5, 0, 1)\n",
    "print('Acuuracy:', accuracy_score(y_test_norm, y_pred_cnn_filt_pool))\n",
    "print('AUC:', roc_auc_score(y_test_norm, y_pred_cnn_filt_pool))\n",
    "\n",
    "# Graficamos la evolución de error (Logic Loss)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros_pool.epoch, registros_pool.history['loss'], linewidth=3, label='training Log-Loss')\n",
    "plt.plot(registros_pool.epoch, registros_pool.history['val_loss'], linewidth=3, label='test Log-Loss')\n",
    "plt.xticks(registros_pool.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('La evolución de error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos la evolución del porcentaje de acierto (Accuracy)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(registros_pool.epoch, registros_pool.history['accuracy'], linewidth=3, label='training Accuracy')\n",
    "plt.plot(registros_pool.epoch, registros_pool.history['val_accuracy'], linewidth=3, label='test Accuracy')\n",
    "plt.xticks(registros_pool.epoch)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('La evolución del porcentaje de acierto')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa124e3",
   "metadata": {
    "id": "1aa124e3"
   },
   "source": [
    "Podemos observar que el modelo resultante con dos capas de _Max-Pooling_ tiene unos resultados muy aceptables, a pesar de tener un número menor de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86d261",
   "metadata": {
    "id": "8c86d261",
    "outputId": "6e38b820-57d2-425d-a6de-73210814a309",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"El número total de los parámetros de la red (modelo_dnn): \", modelo_dnn.count_params())\n",
    "print(\"El número total de los parámetros de la red (modelo_cnn): \", modelo_cnn.count_params())\n",
    "print(\"El número total de los parámetros de la red (modelo_cnn2): \", modelo_cnn2.count_params())\n",
    "print(\"El número total de los parámetros de la red (modelo_cnn_pool): \", modelo_cnn_pool.count_params())\n",
    "\n",
    "print(\"El modelo con Max-Pooling es %.1f veces más pequeño que el último modelo\" % (modelo_cnn2.count_params()/modelo_cnn_pool.count_params()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42532",
   "metadata": {
    "id": "70a42532"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0e73f",
   "metadata": {
    "id": "87d0e73f"
   },
   "source": [
    "### **`Ejercicio 17.2`**\n",
    "\n",
    "Saca la gráfica del **Learning Curve** con la estructura del último modelo analizado en la sesión (`modelo_cnn_pool`), definiendo y aplicando una función nueva considerando los siguientes puntos. Analiza y compara los resultados entre diferentes curvas y explica el modelo que se puede elegir como mejor clasificador:\n",
    "- La función toma solamente una entrada para el hiperparámetro `epochs`con `1` como el valor por defecto. Dibuja diferentes curvas para distintos números de iteraciones (_`epochs`_: `{1, 2, 3}`)\n",
    "- La curva muestra la evolución de `Accuracy` tanto para el conjunto de _training_ como para el dataset de _test_\n",
    "- `semilla=333`,\n",
    "- `batch_size=1000`,\n",
    "- `umbral=0.5`\n",
    "- (*Sugerencia*: No incluyas más de `5` puntos en el eje horizontal y empieza la gráfica con un mínimo de _100_ muestras para los modelos que se van a ajustar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3554b0",
   "metadata": {
    "id": "6b3554b0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Solución\n",
    "# Ejercicio 17.2\n",
    "def generate_learning_curve(epoch:int=1):\n",
    "    import random\n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras import Input\n",
    "    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "    from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "    from keras.backend import clear_session\n",
    "\n",
    "    # Resetear el estado global de keras\n",
    "    clear_session()\n",
    "\n",
    "    # Fijar la semilla para conseguir la reproducibilidad de los resultados\n",
    "    semilla = 333\n",
    "    random.seed(semilla)   # Fijar la semilla a nivel de `python`\n",
    "    np.random.seed(semilla)  # Fijar la semilla a nivel de `numpy`  \n",
    "    tf.random.set_seed(semilla)  # Fijar la semilla a nivel de `tensorflow`\n",
    "    # Declarar el modelo que se va a crear\n",
    "    modelo_cnn_pool = Sequential()\n",
    "    modelo_cnn_pool.add(Input(shape=x_train[0].shape))\n",
    "    modelo_cnn_pool.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "    modelo_cnn_pool.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    modelo_cnn_pool.add(Conv2D(filters=36, kernel_size=(5,5), activation='relu'))\n",
    "    modelo_cnn_pool.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    modelo_cnn_pool.add(Flatten())\n",
    "    modelo_cnn_pool.add(Dense(128, activation='relu'))\n",
    "    modelo_cnn_pool.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compilar e indicar los ajustes del modelo\n",
    "    modelo_cnn_pool.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "    # Consultar el resumen del modelo definido\n",
    "    modelo_cnn_pool.summary()\n",
    "\n",
    "    # Ajustar el modelo a los datos del entrenamiento.\n",
    "    registros_pool = modelo_cnn_pool.fit(x_train, y_train_norm, validation_data=(x_test, y_test_norm), epochs=epoch, batch_size=1000)\n",
    "\n",
    "    # Calcular las predicciones para el conjunto de test \n",
    "    y_pred_cnn_pool = modelo_cnn_pool.predict(x_test)\n",
    "\n",
    "\n",
    "    # Filtrar las predicciones y evaluar el modelo\n",
    "    y_pred_cnn_filt_pool = np.where(y_pred_cnn_pool < 0.5, 0, 1)\n",
    "    print('Acuuracy:', accuracy_score(y_test_norm, y_pred_cnn_filt_pool))\n",
    "    print('AUC:', roc_auc_score(y_test_norm, y_pred_cnn_filt_pool))\n",
    "    \n",
    "    \n",
    "    # Crear un listado de los tamaños de subconjuntos de datos de entrenamiento\n",
    "    num_samples = np.linspace(100,x_train.shape[0],5).astype(int)\n",
    "\n",
    "    # Generamos previamente los vectores necesarios para ir calculando y guardando el rendimiento\n",
    "    train_score = np.zeros(num_samples.size) \n",
    "    test_score = np.zeros(num_samples.size)\n",
    "\n",
    "\n",
    "    for i in range(num_samples.size):\n",
    "      \n",
    "\n",
    "        # Calculamos el área bajo la curva de funcionamiento del receptor sobre datos de train y de test\n",
    "        train_score[i] = accuracy_score(y_train_norm[:num_samples[i]], modelo_cnn_pool.predict(x_train[:num_samples[i]])) \n",
    "        test_score[i] = accuracy_score(y_test_norm, modelo_cnn_pool.predict(x_test))\n",
    "\n",
    "    print(\"La diferencia final del rendimiento del modelo entre training y test es= \", train_score[-1]-test_score[-1])\n",
    "\n",
    "    # Graficamos el rendimiento de training versus de test\n",
    "    plt.plot(num_samples, test_score, label = 'Test Accuracy')\n",
    "    plt.plot(num_samples, train_score, label = 'Train Accuracy')\n",
    "    plt.title('Curva de aprendizaje (Learning Curve) para el modelo_svc')\n",
    "    plt.xlabel('Tamaño de entrenamiento (Training size)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc = 'lower right')  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092fa8c",
   "metadata": {
    "id": "e092fa8c",
    "outputId": "9ff14ddb-f990-4c9d-ab81-953430e9f0fa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "generate_learning_curve(3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd755ef5c364b0937fa7f305ca71365387f816473e8af8795860aa053b94a5ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
